# WAL
In memora DB the WAL is in memory and its sole purpose is to ensure consistency and not durability. When all replicas have reached to a particular version, any version including and lower than that will be cleared out of the WAL, the replicas include only the healthy ones, when a replica is dead it's version is not considered at the bound. There will be APIs that allow replicas to read from this WAL given a version number. 

# Heartbeat

A replica will know about other primaries in the cluster and any change that happens in primaries will also be propagated but the replica will only send heartbeats to its peers, ie., other nodes that are the replica of the it's own primary. And the replica will send heartbeats to a selected few random nodes which always includes the primary and sends status about itself and other nodes it knows about. Data such as the Node ID, version, the nodes heartbeat counter, and last seen timestamp and an epoch is gossiped. When the heartbeat counter goes above 10000 the node enters a new epoch and the heartbeat is made to 1. When a node recieves information about a node it checks if the epoch is greater than its known one, if no then it checks if the heartbeat is greater, if yes then it'll update, if no then the node is in a grace period. After a jitter random time the node if not updated will be marked as pdead. After another grace period the node is marked dead. When a dead status bubbles up to the primary the primary removes the replica, once it gets (N / 2) + 1 votes saying it is dead. Even though the death status bubbles up eventually this doesn't affect read or writes made to the primary buckets. Since the pdead replica would have never caught up to the primary's version, hence no read will be routed to it. 

If the node comes back up it'll check it's persistent peers. Yes only peers and other primaries will be persisted. If there are peers and it knows about its primary it'll immediately go to the primary to tell the primary it has come back up. The primary will let it in as long as it still doesn't have enough replicas. If it was filled in with enough replicas it will give the node that came up to any other unhealthy primary. When the replica connects with any primary. It'll start advertising it's back again to all it's peers with epoch 0 and heartbeat 1. If all primaries are healthy, then the replica is made to wait to check if it is infact healthy. If it is actually healthy, then it will be made a new primary, following the SCALE UP protocol.

Since every node sends heartbeats to the primary, it will be a special kind of heartbeat, it will expect a response back unlike other heartbeats. Since the replica expects a response when the primary goes down and doesn't respond for a certain amount of time it'll be marked as pdead by the node. After another threshold the node will be marked as dead.

dead is a special status that has a vote. When a node sends out it's gossip it doesn't send out the vote count it has. But when a node recieves the gossip finds a node marked as dead and it has also marked the node as dead it'll increase the vote count it has with itself. 

When a replica goes down and the primary gets replica / 2 + 1 votes the replica will be removed. Likewise when the primary is down, the replicas enter a consensus protocol. A node can only vote once and the node will vote to the node which according to it has the highest version, if there's a conflict a lexicographically sorted first replica will get the vote. And when a replica gets N / 2 + 1 votes it'll mark itself as the primary with an increased primary epoch and will say to other primaries that it has been promoted and likewise to it's replicas.

Now when the primary which went down comes back up, tries to call the replicas and the term of the primary is lesser, yes the term also will be persisted. The old primary will either become a replica of the current primary or any other primary that needs it. Again if here the cluster is healthy, the node will be made to wait to check its healthiness, and then will initiate a SCALE UP protocol.

When a primary goes down, and the other primaries know that this primary has atleast one replica, they do not do anything and only wait, whenever a read request comes targeting the failed primary the read is directed to any of the known replica, the replica then internally forwards the request to its known highest version replica and then this request is handled and then returned. Any writes that target the failed primary will fail until any of the replica promotes itself to a primary, it will say basically like this "PRIMARY_DOWN". 

But when a primary goes down, and other primaries know that this primary did not have a replica, it basically means that there is no current owner for buckets owned by the fallen primary. The primary with its buckets are simply removed from the bucket map. Yes this will cause cache misses on nodes ordered after this node failure in the list. But as mentioned we do not ensure durability. After a node goes down, a node knows if it is after the removed node in the sorted list, because it has the list. If it is after the fallen node, it will start a thread and remove all keys it has that now do not belong to it.